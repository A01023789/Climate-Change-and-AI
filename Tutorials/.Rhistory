set.seed(123)
#mtry es para que considere los 13 predictores sean parte del árbol, importance true para que de la importancia de cada una de las variables dentro del modelo
bag.boston<-randomForest(medv~.,data=Boston,subset=train,mtry=13,importance=TRUE)
bag.boston
#Realizar la comparación con el conjunto de prueba
boston.pred.bag <- predict(bag.boston, newdata=Boston.data.test)
#Diferencia
plot(boston.pred.bag, boston.test)
abline(0,1)
#Calcular el valor medio al cuadrado
mean((boston.pred.bag-boston.test)^2)
#Correr con menos para ver si se reduce el error
#ntree para indicar el número de árboles que quiero
set.seed(123)
bag.boston<-randomForest(medv~.,data=Boston,subset=train,mtry=13,ntree=25)
boston.pred.bag <- predict(bag.boston, newdata=Boston.data.test)
mean((boston.pred.bag-boston.test)^2)
#Disminuir el número de predictores a 6
set.seed(123)
rf.boston<-randomForest(medv~.,data=Boston,subset=train,mtry=6,importance =TRUE)
boston.pred.rf <- predict(rf.boston ,newdata=Boston.data.test)
mean((boston.pred.rf-boston.test)^2)
#Conocer la importancia de los predictores que se están utilizando
importance(rf.boston)
varImpPlot(rf.boston)
importance(rf.boston)
varImpPlot(rf.boston)
library(gbm)
library(gbm)
#Hace una interacción mucho más grande de la información para obtener resultados más confiables
set.seed(123)
boost.boston<-gbm(medv~.,data=Boston[train,],
distribution="gaussian",n.trees=5000,interaction.depth=4)
library(gbm)
#Hace una interacción mucho más grande de la información para obtener resultados más confiables
set.seed(123)
#Aquí el conjunto de datos se pone directamente
boost.boston<-gbm(medv~.,data=Boston[train,],
distribution="gaussian",n.trees=5000,interaction.depth=4)
#Para árbol de regresión se utiliza gaussian
#Para árbol de clasificación se utiliza "bernoulli"
summary(boost.boston)
par(mfrow=c(1,2))
#Plot solo de las variables más importantes
plot(boost.boston, i="rm")
plot(boost.boston, i="lstat")
library(tree)
library(ISLR)
attach(OJ)
summary(OJ)
library(tree)
library(ISLR)
attach(OJ)
summary(OJ)
set.seed(555)
trainT<-sample(1:nrow(OJ),800)
OJ.test<-OJ[-train,]
tree.OJT<-tree(Purchase~.,OJ,subset=train)
summary(tree.OJT)
tree.OJT<-tree(Purchase~.,OJ,subset=trainT)
summary(tree.OJT)
#Se puede apreciar que
plot(tree.OJT)
text(tree.OJT,pretty = 0)
?OJ
OJ.predT<- predict(tree.OJT,newdata = OJ.test,type="class")
table(OJ.predT,OJ.test$Purchase)
OJ.predT<- predict(tree.OJT,newdata = OJ.test,type="class")
table(OJ.predT,OJ.test$Purchase)
OJ.predT<- predict(tree.OJT, newdata = OJ.test,type="class")
table(OJ.predT,OJ.test$Purchase)
OJ.predT<- predict(tree.OJT, newdata = OJ.test,type="class")
table(OJ.predT,OJ.test$Purchase)
set.seed(555)
OJ.predT<- predict(tree.OJT, newdata = OJ.test,type="class")
table(OJ.predT,OJ.test$Purchase)
set.seed(555)
OJ.predT<- predict(tree.OJT, newdata = OJ.test,type="class")
table(OJ.predT,OJ.test$Purchase)
set.seed(555)
OJ.predT<- predict(tree.OJT, newdata = OJ.test,type="class")
table(OJ.predT,OJ.test$Purchase)
library(tree)
library(ISLR)
attach(OJ)
summary(OJ)
set.seed(555)
trainT<-sample(1:nrow(OJ),800)
OJ.test<-OJ[-train,]
set.seed(555)
tree.OJT<-tree(Purchase~.,OJ,subset=trainT)
summary(tree.OJT)
#Se puede apreciar que la tasa de error de entrenamiento es de 13.75% y la cantidad de nodos terminales del árbol es de 9
plot(tree.OJT)
text(tree.OJT,pretty = 0)
#Gracias a la gráfica se puede apreciar que la variable más significativa para explicar si alguien eligió comprar Citrus Hill o Minute Maid es LoyalCH que indica la fidelidad de los clientes a la marca Citrus Hill
#Posteriormente, la variable más significativa es la diferencia de precios entre una marca y otra.
set.seed(555)
OJ.predT<- predict(tree.OJT, newdata = OJ.test,type="class")
table(OJ.predT,OJ.test$Purchase)
library(tree)
library(ISLR)
attach(OJ)
View(OJ)
summary(OJ)
set.seed(555)
train<-sample(1:nrow(OJ), 800)
OJ.test<-OJ[-train, ]
library(tree)
library(ISLR)
attach(OJ)
summary(OJ)
set.seed(555)
train<-sample(1:nrow(OJ), 800)
OJ.test<-OJ[-train, ]
tree.OJ<-tree(Purchase~.,OJ,subset=train)
summary(tree.OJ)
#Se puede apreciar que la tasa de error de entrenamiento es de 13.75% y la cantidad de nodos terminales del árbol es de 9
plot(tree.OJ)
text(tree.OJ, pretty=0)
#Gracias a la gráfica se puede apreciar que la variable más significativa para explicar si alguien eligió comprar Citrus Hill o Minute Maid es LoyalCH que indica la fidelidad de los clientes a la marca Citrus Hill
#Posteriormente, la variable más significativa es la diferencia de precios entre una marca y otra.
OJ.pred<-predict(tree.OJ,newdata=OJ.test, type = "class")
table(OJ.pred,OJ.test$Purchase)
OJ.pred<-predict(tree.OJ,newdata=OJ.test, type = "class")
table(OJ.pred,OJ.test$Purchase)
#Gracias a la matriz de confusión podemos sacar la tasa de error de la prueba
(28+31)/270
OJ.pred<-predict(tree.OJ,newdata=OJ.test, type = "class")
table(OJ.pred,OJ.test$Purchase)
#Gracias a la matriz de confusión podemos sacar la tasa de error de la prueba
(28+31)/270
#La tasa de error de la prueba es del 21.8%
cv.tree.OJ<-cv.tree(tree.OJ,FUN=prune.misclass)
plot(cv.tree.OJ$size,cv.tree.OJ$dev)
prune.OJ<-prune.tree(tree.OJ, best=5)
plot(prune.OJ)
text(prune.OJ, pretty=0)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(tree)
library(ISLR)
attach(Carseats)
High<-ifelse(Sales <=8,"No","Yes")
Carseats<-data.frame(Carseats,High)
class(Carseats$High)
Carseats$High = as.factor(Carseats$High)
class(Carseats$High)
tree.carseats<-tree(High~.-Sales, data=Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats, pretty=0, cex=0.5)
tree.carseats
set.seed(123)
train<-sample(1:nrow(Carseats), 200)
Carseats.test<-Carseats[-train, ]
High.test<-High[-train]
tree.carseats<-tree(High~.-Sales,Carseats,subset=train)
tree.pred<-predict(tree.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
(87+65)/200
set.seed(123)
cv.carseats<-cv.tree(tree.carseats,FUN=prune.misclass)
names(cv.carseats)
cv.carseats
plot(cv.carseats$size ,cv.carseats$dev ,type="b")
prune.carseats<-prune.misclass(tree.carseats,best=8)
plot(prune.carseats)
text(prune.carseats,pretty=0)
tree.pred<-predict(prune.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
#3
(85+58)/200
#8
(88+66)/200
#13
(86+65)/200
prune.carseats<-prune.misclass(tree.carseats, best=13)
plot(prune.carseats)
text(prune.carseats, pretty=0)
tree.pred<-predict(prune.carseats, Carseats.test, type="class")
table(tree.pred, High.test)
(86+65)/200
prune.carseats<-prune.misclass(tree.carseats, best=13)
plot(prune.carseats)
text(prune.carseats, pretty=0)
tree.pred<-predict(prune.carseats, Carseats.test, type="class")
table(tree.pred, High.test)
(86+65)/200
library(MASS)
set.seed(123)
train <- sample(1:nrow(Boston), nrow(Boston)/2)
Boston.data.test<-Boston[-train, ]
tree.boston<-tree(medv~., data=Boston, subset=train)
summary(tree.boston)
plot(tree.boston)
text(tree.boston, pretty=0)
cv.boston<-cv.tree(tree.boston)
plot(cv.boston$size, cv.boston$dev, type="b")
prune.boston<-prune.tree(tree.boston, best=4)
plot(prune.boston)
text(prune.boston, pretty=0)
tree.boston
boston.pred<-predict(tree.boston, newdata=Boston.data.test)
boston.test<-Boston[-train,"medv"]
sqrt(mean((boston.pred-boston.test)^2))
library(randomForest)
set.seed(123)
bag.boston<-randomForest(medv~.,data=Boston,subset=train,mtry=13,importance=TRUE)
bag.boston
boston.pred.bag <- predict(bag.boston, newdata=Boston.data.test)
plot(boston.pred.bag, boston.test)
abline(0,1)
mean((boston.pred.bag-boston.test)^2)
set.seed(123)
bag.boston<-randomForest(medv~.,data=Boston,subset=train,mtry=13,ntree=25)
boston.pred.bag <- predict(bag.boston, newdata=Boston.data.test)
mean((boston.pred.bag-boston.test)^2)
set.seed(123)
rf.boston<-randomForest(medv~.,data=Boston,subset=train,mtry=6,importance =TRUE)
boston.pred.rf <- predict(rf.boston ,newdata=Boston.data.test)
mean((boston.pred.rf-boston.test)^2)
importance(rf.boston)
varImpPlot(rf.boston)
library(gbm)
set.seed(123)
boost.boston<-gbm(medv~.,data=Boston[train,],
distribution="gaussian",n.trees=5000,interaction.depth=4)
summary(boost.boston)
library(tree)
library(ISLR)
attach(OJ)
View(OJ)
summary(OJ)
set.seed(555)
train<-sample(1:nrow(OJ), 800)
OJ.test<-OJ[-train, ]
treeOJ<-tree(Purchase~.,OJ,subset=train)
summary(treeOJ)
#Tasa error de train = 0.137
#Nodos: 9
plot(treeOJ)
text(treeOJ, pretty=0)
OJpred<-predict(treeOJ,newdata=OJ.test, type = "class")
table(OJpred,OJ.test$Purchase)
(28+31)/270
#0.218 tasa error
cv.tree.oj <- cv.tree(treeOJ,FUN=prune.misclass)
plot(cv.tree.oj$size,cv.tree.oj$dev)
#El tamaño 5 es el árbol que tiene una menor tasa de error de clasificaión válida cruzada. A partir del tamaño 2 el error se minimiza, pero sigue manteniendose constante en el tamaño 5, aunque con la menor tasa de error entre todos los tamaós. Por todo esto, el tamaño óptimo es 5 como ha sido mencionado anteriormente, evitando la sobreramificación.
#Validación cruzada:
#Si conduce a un árbol podado (de 9 nodos inicialmente). El arbol nos indica que el más óptimo y el mejor es de 5 nodos.
prune.OJ<-prune.tree(treeOJ, best=5)
plot(prune.OJ)
text(prune.OJ, pretty=0)
library(ISLR)
attach(OJ)
View(OJ)
summary(OJ)
set.seed(555)
train<-sample(1:nrow(OJ), 800)
OJ.test<-OJ[-train, ]
library(tree)
library(ISLR)
attach(OJ)
summary(OJ)
set.seed(555)
train<-sample(1:nrow(OJ), 800)
OJ.test<-OJ[-train, ]
install.packages(c("httr", "jsonlite"))
library(httr)
library(jsonlite)
url <- "https://www.climatewatchdata.org/api/v1/data/ndc_content"
resNDC <- GET(url)
NDCdata<-fromJSON(rawToChar(resNDC$content))
str(NDCdata)
str(resNDC)
?GET
resNDC<-GET(url,query= list(countries = "EUU", page=1))
NDCdata<-fromJSON(rawToChar(resNDC$content))
class(NDCdata)
str(NDCdata)
str(resNDC)
total<-as.numeric(resNDC$headers$total)
per.page<-as.numeric(resNDC$headers['per-page'])
pages<-ceiling(total/per.page)
resNDC<-GET(url,query= list(countries = "EUU", page=1))
NDCdata<-fromJSON(rawToChar(resNDC$content))$data
for(i in 2:pages)
{
resNDC<-GET(url,query= list(countries = "EUU", page=i))
pivot<-fromJSON(rawToChar(resNDC$content))$data
NDCdata<-rbind(NDCdata,pivot)
}
dim(NDCdata)
NDCdata.best<-lapply(c(1:pages),function(x){
resNDC<-GET(url,query= list(countries = "EUU", page=x));
fromJSON(rawToChar(resNDC$content))$data
}
)
NDCdata.best<-do.call(rbind,NDCdata.best)
dim(NDCdata.best)
colnames(NDCdata)
names(NDCdata)
summary(NDCdata)
unique(NDCdata$iso_code3)
sapply(NDCdata,unique)
sapply(NDCdata,max)
NamesC<-
for (i in 1:length(NamesC))
{
NDCdata.best<-lapply(c(1:pages),function(x){
resNDC<-GET(url,query= list(countries = NamesC[i] , page=x));
fromJSON(rawToChar(resNDC$content))$data
}
)
NDCdata.best<-do.call(rbind,NDCdata.best)
}
library(httr)
library(jsonlite)
url <- "https://www.climatewatchdata.org/api/v1/data/ndc_content"
resNDC <- GET(url)
total<-as.numeric(resNDC$headers$total)
per.page<-as.numeric(resNDC$headers['per-page'])
pages<-ceiling(total/per.page)
NDCdata.best<-lapply(c(1:pages),function(x){
resNDC<-GET(url,query= list(page=x));
fromJSON(rawToChar(resNDC$content))$data
}
)
NDCdata.best<-do.call(rbind,NDCdata.best)
dim(NDCdata.best)
nations<-unique(NDCdata.best$iso_code3)
NDCdata.best<-lapply(c(1:pages),function(x){
resNDC<-GET(url,query= list(page=x));
fromJSON(rawToChar(resNDC$content))$data
}
NDCdata.best<-lapply(c(1:pages),function(x){
resNDC<-GET(url,query= list(page=x));
fromJSON(rawToChar(resNDC$content))$data
}
)
install.packages(c("httr", "jsonlite"))
install.packages(c("httr", "jsonlite"))
library(httr)
library(jsonlite)
url <- "https://www.climatewatchdata.org/api/v1/data/ndc_content"
resNDC <- GET(url)
NDCdata<-fromJSON(rawToChar(resNDC$content))
str(NDCdata)
str(resNDC)
?GET
library(httr)
library(jsonlite)
url <- "https://www.climatewatchdata.org/api/v1/data/ndc_content"
resNDC <- GET(url)
NDCdata<-fromJSON(rawToChar(resNDC$content))
str(NDCdata)
str(resNDC)
?GET
resNDC<-GET(url,query= list(countries = "EUU", page=1))
NDCdata<-fromJSON(rawToChar(resNDC$content))
class(NDCdata)
str(NDCdata)
str(resNDC)
total<-as.numeric(resNDC$headers$total)
per.page<-as.numeric(resNDC$headers['per-page'])
pages<-ceiling(total/per.page)
resNDC<-GET(url,query= list(countries = "EUU", page=1))
NDCdata<-fromJSON(rawToChar(resNDC$content))$data
for(i in 2:pages)
{
resNDC<-GET(url,query= list(countries = "EUU", page=i))
pivot<-fromJSON(rawToChar(resNDC$content))$data
NDCdata<-rbind(NDCdata,pivot)
}
dim(NDCdata)
NDCdata.best<-lapply(c(1:pages),function(x){
resNDC<-GET(url,query= list(countries = "EUU", page=x));
fromJSON(rawToChar(resNDC$content))$data
}
)
NDCdata.best<-do.call(rbind,NDCdata.best)
im(NDCdata.best)
dim(NDCdata.best)
colnames(NDCdata)
names(NDCdata)
summary(NDCdata)
unique(NDCdata$iso_code3)
sapply(NDCdata,unique)
sapply(NDCdata,max)
NamesC<-
for (i in 1:length(NamesC))
{
NDCdata.best<-lapply(c(1:pages),function(x){
resNDC<-GET(url,query= list(countries = NamesC[i] , page=x));
fromJSON(rawToChar(resNDC$content))$data
}
)
NDCdata.best<-do.call(rbind,NDCdata.best)
}
url <- "https://www.climatewatchdata.org/api/v1/data/ndc_content"
resNDC <- GET(url)
total<-as.numeric(resNDC$headers$total)
per.page<-as.numeric(resNDC$headers['per-page'])
pages<-ceiling(total/per.page)
NDCdata.best<-lapply(c(1:pages),function(x){
resNDC<-GET(url,query= list(page=x));
fromJSON(rawToChar(resNDC$content))$data
}
)
NDCdata.best<-do.call(rbind,NDCdata.best)
root<-"/Users/marianacornejo/Documents/GitHub/Climate-Change-and-AI/Data/NDC/Raw//"
file.names <- list.files(path =root, pattern = ".csv")
NDCData<-lapply(file.names,function(x){read.csv(paste0(root,x))})
NDCData<-do.call("rbind",NDCData)
View(NDCData)
View(NDCData)
indicators<-unique(NDCData$indicator_name)
indicators
indicators_names<-gsub("/","_",indicators)
indicators_names<-gsub(" ","_",indicators_names)
indicators_names<-gsub("\\(","_",indicators_names)
indicators_names<-gsub("\\)","_",indicators_names)
indicators_names<-gsub("%","",indicators_names)
indicators_names<-gsub(":","",indicators_names)
?gsub
i<-1
explore<-subset(NDCData,indicator_name==indicators[i])
explore$count<-1
explore<-aggregate(list(count=explore$count),list(
global_category=explore$global_category,
indicator_name=explore$indicator_name,
value=explore$value
),sum)
explore<-explore[order(-explore$count),]
View(explore)
View(explore)
i<-10
explore<-subset(NDCData,indicator_name==indicators[i])
explore$count<-10
explore<-aggregate(list(count=explore$count),list(
global_category=explore$global_category,
indicator_name=explore$indicator_name,
value=explore$value
),sum)
explore<-explore[order(-explore$count),]
View(explore)
View(explore)
i<-1
explore<-subset(NDCData,indicator_name==indicators[i])
explore$count<-1
explore<-aggregate(list(count=explore$count),list(
global_category=explore$global_category,
indicator_name=explore$indicator_name,
value=explore$value
),sum)
explore<-explore[order(-explore$count),]
null.values<-c("No Document Submitted","No specified measure")
NDCData$value.numeric<-ifelse(NDCData$value==null.values[1],-1,1)
NDCData$value.numeric<-ifelse(NDCData$value==null.values[2],0,1)
explore<-aggregate(list(value.numeric=NDCData$value.numeric),list(
global_category=NDCData$global_category,
indicator_name=NDCData$indicator_name
),sum)
View(explore)
View(explore)
explore<-subset(explore,global_category=="Mitigation")   #Mitigation
explore<-explore[order(-explore$value.numeric),]
explore
View(explore)
View(explore)
explore<-subset(explore,global_category=="Waste")   #Waste
explore<-explore[order(-explore$value.numeric),]
explore
View(explore)
View(explore)
explore<-subset(explore,global_category=="Mitigation")   #Mitigation
explore<-explore[order(-explore$value.numeric),]
explore
View(explore)
View(explore)
explore<-aggregate(list(value.numeric=NDCData$value.numeric),list(
global_category=NDCData$global_category,
indicator_name=NDCData$indicator_name
),sum)
explore<-subset(explore,global_category=="Mitigation")   #Mitigation
explore<-explore[order(-explore$value.numeric),]
explore
explore<-aggregate(list(value.numeric=NDCData$value.numeric),list(
global_category=NDCData$global_category,
country=NDCData$country
),sum)
View(explore)
explore<-subset(explore,global_category=="Adaptation")   #Mitigation
explore<-explore[order(-explore$value.numeric),]
explore
View(explore)
View(explore)
out<-"/Users/marianacornejo/Documents/GitHub/Climate-Change-and-AI/Data/NDC/Indicators\\"
for (i in 1:length(indicators))
{
explore<-subset(NDCData,indicator_name==indicators[i])
explore$count<-1
explore<-aggregate(list(count=explore$count),list(
global_category=explore$global_category,
indicator_name=explore$indicator_name,
value=explore$value
),sum)
explore<-explore[order(-explore$count),]
write.csv(explore,paste0(out,indicators_names[i],".csv"),row.names=FALSE)
}
